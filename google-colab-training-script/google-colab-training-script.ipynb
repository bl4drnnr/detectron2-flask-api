{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "od9mWMTxZstB",
        "outputId": "893ca5e8-be85-4110-9ba3-319378b178c4"
      },
      "outputs": [],
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuoZPt2AdfnU",
        "outputId": "9d9862f5-5f4a-4b48-ed2f-403e0c2d01b6"
      },
      "outputs": [],
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4c4ngVed3o7"
      },
      "outputs": [],
      "source": [
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M86dPQOye_gl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyMpFXRmfFlT"
      },
      "outputs": [],
      "source": [
        "!unzip data.zip > /dev/null > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5db_jcjfFnn"
      },
      "outputs": [],
      "source": [
        "config_file_path = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
        "checkpoint_url = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"\n",
        "\n",
        "output_dir = \"./output/object_detection\"\n",
        "num_classes = 1\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "train_dataset_name = \"train_set\"\n",
        "train_images_path = \"./data/train\"\n",
        "train_json_annot_path = \"./data/train.json\"\n",
        "\n",
        "test_dataset_name = \"test_set\"\n",
        "test_images_path = \"./data/test\"\n",
        "test_json_annot_path = \"./data/test.json\"\n",
        "\n",
        "cfg_save_path = \"OD_mask_rcnn_101_50_cfg.pickle\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iW7f_PWIfFpt"
      },
      "outputs": [],
      "source": [
        "from detectron2.data.datasets import register_coco_instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcIsyFAdfFry"
      },
      "outputs": [],
      "source": [
        "register_coco_instances(name = train_dataset_name, metadata = {}, json_file = train_json_annot_path, image_root = train_images_path)\n",
        "register_coco_instances(name = test_dataset_name, metadata = {}, json_file = test_json_annot_path, image_root = test_images_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkQEcFihfFtn"
      },
      "outputs": [],
      "source": [
        "def plot_samples(dataset_name, n = 1):\n",
        "  dataset_custom = DatasetCatalog.get(dataset_name)\n",
        "  dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
        "\n",
        "  for s in random.sample(dataset_custom, n):\n",
        "    img = cv2.imread(s[\"file_name\"])\n",
        "    v = Visualizer(img[:,:,::-1], metadata = dataset_custom_metadata, scale = 0.5)\n",
        "    v = v.draw_dataset_dict(s)\n",
        "    plt.figure(figsize=(15,20))\n",
        "    plt.imshow(v.get_image())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aCYq4NBwhwKV",
        "outputId": "21c9bd7d-6124-4a69-a780-194849b134c2"
      },
      "outputs": [],
      "source": [
        "plot_samples(dataset_name=train_dataset_name, n=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHTCI60hhwMY"
      },
      "outputs": [],
      "source": [
        "def get_traing_cfg(\n",
        "    config_file_path,\n",
        "    checkpoint_url,\n",
        "    train_dataset_name,\n",
        "    test_dataset_name,\n",
        "    num_classes,\n",
        "    device,\n",
        "    output_dir\n",
        "):\n",
        "  cfg = get_cfg()\n",
        "\n",
        "  cfg.merge_from_file(model_zoo.get_config_file(config_file_path))\n",
        "  cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(checkpoint_url)\n",
        "\n",
        "  cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
        "  cfg.DATASETS.TEST = (test_dataset_name,)\n",
        "\n",
        "  cfg.DATALOADER.NUM_WORKERS = 2\n",
        "\n",
        "  cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "  cfg.SOLVER.BASE_LR = 0.00025\n",
        "  cfg.SOLVER.MAX_ITER = 500\n",
        "  cfg.SOLVER.STEPS = []\n",
        "\n",
        "  cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
        "  cfg.MODEL.DEVICE = device\n",
        "\n",
        "  cfg.OUTPUT_DIR = output_dir\n",
        "\n",
        "  return cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaQTDgqehwQT"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from detectron2.engine import DefaultTrainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE-wwLjsj7tB"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "  cfg = get_traing_cfg(\n",
        "      config_file_path,\n",
        "      checkpoint_url,\n",
        "      train_dataset_name,\n",
        "      test_dataset_name,\n",
        "      num_classes,\n",
        "      device,\n",
        "      output_dir\n",
        "  )\n",
        "\n",
        "  with open(cfg_save_path, 'wb') as f:\n",
        "    pickle.dump(cfg, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "  trainer = DefaultTrainer(cfg)\n",
        "  trainer.resume_or_load(resume=False)\n",
        "\n",
        "  trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uC6n3uw8j7vD",
        "outputId": "b76ab38a-c4aa-4d26-81b5-5f1d577f7fa2"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haAQQi_enPqF"
      },
      "outputs": [],
      "source": [
        "with open(cfg_save_path, 'rb') as f:\n",
        "  cfg = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW0GjFhlnPsI",
        "outputId": "1cfd0ffd-e465-49e3-c82e-87f9a051f96c"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, 'model_final.pth')\n",
        "\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1\n",
        "\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IlUDqGnWnPwT"
      },
      "outputs": [],
      "source": [
        "# FUNCTION 1 - display of N sample images (original ones from TRAIN data with ANNOTATION(s))\n",
        "\n",
        "def plot_samples(dataset_name, n = 1):\n",
        "  dataset_custom = DatasetCatalog.get(dataset_name)\n",
        "  dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
        "\n",
        "  for s in random.sample(dataset_custom, n):\n",
        "    img = cv2.imread(s[\"file_name\"])\n",
        "    v = Visualizer(img[:,:,::-1], metadata = dataset_custom_metadata, scale = 0.5)\n",
        "    v = v.draw_dataset_dict(s)\n",
        "    plt.figure(figsize=(15,20))\n",
        "    plt.imshow(v.get_image())\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILXxkq_GnPyZ"
      },
      "outputs": [],
      "source": [
        "# FUNCTION 2 - display image with original annotations (i.e., original BoundingBox)\n",
        "# dataset_name - train_dataset_name OR test_dataset_name\n",
        "\n",
        "def plot_annotation(dataset_name, image_path, num=0):\n",
        "  dataset_custom = DatasetCatalog.get(dataset_name)\n",
        "  dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
        "\n",
        "  img = cv2.imread(image_path)\n",
        "  v = Visualizer(img[:,:,::-1], metadata=dataset_custom_metadata, scale = 0.5)\n",
        "  v = v.draw_dataset_dict(dataset_custom[num])\n",
        "  plt.figure(figsize=(15, 20))\n",
        "  plt.imshow(v.get_image())\n",
        "  plt.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xlh5BIUopYEr"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "# FUNCTION 3 - make and show predictions on selected IMAGE\n",
        "def on_image_draw(image_path, predictor):\n",
        "  im = cv2.imread(image_path)\n",
        "  outputs = predictor(im)\n",
        "  v = Visualizer(im[:,:,::-1], metadata={}, scale = 0.5, instance_mode=ColorMode.SEGMENTATION)\n",
        "  v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "  plt.figure(figsize=(15,20))\n",
        "  plt.imshow(v.get_image())\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yffq78lpYHF"
      },
      "outputs": [],
      "source": [
        "# FUNCTION 4 - get SCORE(s) and COORDINATES of BoundingBox(es)\n",
        "def on_image_get_points_scores(image_path, predictor):\n",
        "  im = cv2.imread(image_path)\n",
        "  outputs = predictor(im)\n",
        "\n",
        "  scores = outputs['instances'].scores\n",
        "  scores_all = []\n",
        "\n",
        "  for i in range(len(scores)):\n",
        "    scores_all.append(scores[i].item())\n",
        "\n",
        "  boxes = outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "\n",
        "  return (scores_all, boxes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qk4lI9wpYJF"
      },
      "outputs": [],
      "source": [
        "# FUNCTION 5 - CROP of ROI(s) out of the whole IMAGE\n",
        "from PIL import Image\n",
        "\n",
        "def crop_object(image, box):\n",
        "  x_top_left = box[0]\n",
        "  y_top_left = box[1]\n",
        "  x_bottom_right = box[2]\n",
        "  y_bottom_right = box[3]\n",
        "\n",
        "  x_center = (x_top_left + x_bottom_right) / 2\n",
        "  y_center = (y_top_left + y_bottom_right) / 2\n",
        "\n",
        "  crop_img = image.crop((int(x_top_left), int(y_top_left), int(x_bottom_right), int(y_bottom_right)))\n",
        "\n",
        "  return crop_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WsCvbjuur1UJ",
        "outputId": "071fe90e-0367-4423-b498-0f2145caa05d"
      },
      "outputs": [],
      "source": [
        "check_image_path_test1 = './data/test/20.png'\n",
        "\n",
        "example_image_test_1 = cv2.imread(check_image_path_test1)\n",
        "plt.figure(figsize=(15,20))\n",
        "plt.imshow(cv2.cvtColor(example_image_test_1, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qbH6QShqsJgw",
        "outputId": "15595002-5e98-4b9d-b650-0860a0a100c2"
      },
      "outputs": [],
      "source": [
        "on_image_draw(check_image_path_test1, predictor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSonTZBJsRao"
      },
      "outputs": [],
      "source": [
        "scores_1, boxes_1 = on_image_get_points_scores(check_image_path_test1, predictor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2x9W8KQsXWS",
        "outputId": "1016b35c-f789-4cf0-f7bf-2074782a3883"
      },
      "outputs": [],
      "source": [
        "for i in range(len(scores_1)):\n",
        "  print(f'BOX = ({boxes_1[i]}) \\t SCORES = {scores_1[i]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "uemqRdwNtSgW",
        "outputId": "42a973e1-e423-47f2-fc5c-4fcb736c073b"
      },
      "outputs": [],
      "source": [
        "testing_example_image_converted_1 = cv2.cvtColor(example_image_test_1, cv2.COLOR_BGR2RGB)\n",
        "image_pil_1 = Image.fromarray(testing_example_image_converted_1)\n",
        "\n",
        "for i in range(len(boxes_1)):\n",
        "  box = boxes_1[i]\n",
        "  crop_image_1 = crop_object(image_pil_1, box)\n",
        "\n",
        "  image_np_1 = np.asarray(crop_image_1)\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.imshow(image_np_1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
